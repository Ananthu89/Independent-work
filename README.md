## Contents and theory

The folder 'Standard_vs_beta_VAEs' is for exploring how standard-VAEs (i.e., beta = 1) and Beta-VAEs (any non-zero beta) differ when it comes to disenatangling the factors while visualizing a dataset. The loss functions of both VAEs and Beta-VAEs have reconstruction and similarity loss terms unlike autoencoders (AEs) which have only the former term, measuring the difference between the original input and the output generated by the decoder. The similarity loss is the KL divergence (https://medium.com/@rushikesh.shende/autoencoders-variational-autoencoders-vae-and-%CE%B2-vae-ceba9998773d), measuring the difference between the learned distribution in the latent space and the predefined distribution. 

### Advantage of Beta-VAEs over VAEs 
VAEs can still be difficult to interpret, as the factors encoded in the latent layer are entangled. Beta-VAEs use a multiplier ‘beta’ to the KL divergence which reduces the similarity loss, thus improving the disentanglement in the latent space, but at the cost of a high reconstruction loss (https://openreview.net/pdf?id=Sy2fzU9gl). Although greater disentaglement is connected to greater interpretability (https://openreview.net/pdf?id=Sy2fzU9gl), there may not always be this strong correlation between them (as mentioned in the 'Final remarks' section). 

## Results
I set the 'beta' value to be 4 here for the beta-VAE (as my initial exploration involving lower values, e.g., 'beta' = 1.5, led to a milder disentangling compared to 'beta' = 4). Interestingly, when the number of latent dimensions was only 2, the standard-VAE was at least as comparable as the beta-VAE in disentangling the factors. However, as expected, as I increased the latent dimensions to 10, beta-VAEs showed better disentangling properties. In the Python file for this, there is also a visual at the end showing this. Note that even the number of epochs need to be reasonably high for this to be observed (I used 50). Depending on the input size and the number of latent dimensions, it’s advisable to scale “beta” (https://openreview.net/pdf?id=Sy2fzU9gl). 

The choice of the dataset was because it was publicly available and easy to load (shown in the file titled "...2D..."). For visualizing the latent dimensions, I used a technique called t-SNE, which offers advantages over PCA w.r.t. visualization. The former can capture non-linear relationships in data and is better at revealing clusters, although it's less interpretable than the latter (which is OK as far as the purpose is solely visualization).  

## Final remarks for future work
1. The VAE here is constructed using a fully connected network or multilayer perceptron (MLP), with the layers consisting of linear transformations followed by ReLU non-linear activation functions. Instead of the MLP, the choice of convolutional layers could be a better alternative here, especially because we are dealing with image data. 
2. We could also choose a more complex (or real-life) dataset.
3. While Beta-VAEs can disentangle image data, they may not be good with text data. Hence, we could use other variants of VAEs for text-data.
4. Note that disentanglement is about whether each latent variable encodes a single (generative) factor, whereas interpretability is actually about whether humans can understand and describe the (disentangled) factors. Hence, we need to see if there are separate evaluation metrics for disentanglement (already available) and interpretability. 
